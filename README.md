# Custom_LLM_with_Langchain
 Create a wrapper around your local model or a model loaded from a different source by encapsulating it in a Custom LLM Class rather than going down the same expensive API_KEY path.
